{"cells":[{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":276,"status":"ok","timestamp":1641671474381,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"X4zV9vDx8FEI"},"outputs":[],"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1881,"status":"ok","timestamp":1641671476503,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"-BPrwAWK88qt","outputId":"9b544171-bcfc-44af-d799-ed8715fbcd6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":264,"status":"ok","timestamp":1641671535143,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"DUW2YYWt85vw"},"outputs":[],"source":["data_dir = '/content/drive/MyDrive/Colab Notebooks/ibb_ass3/torch2'\n","model_name = \"resnet\"\n","num_classes = 100\n","batch_size = 10\n","num_epochs = 20\n","feature_extract = True"]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1641671540400,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"9ogiZ04S9akP"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc \u003e best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"]},{"cell_type":"code","execution_count":96,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1641671543815,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"JVsiMZsEFGE-"},"outputs":[],"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1641671545014,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"uiRkioxOFIpR"},"outputs":[],"source":["model = models.resnet50(pretrained=True)\n","feats = model.fc.in_features\n","model.fc = nn.Linear(feats, num_classes)\n"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7761,"status":"ok","timestamp":1641671553678,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"xRMp5_VVYPHP","outputId":"d4d56962-4512-40fb-ae5e-d0d74081bf06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing Datasets and Dataloaders...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1641671558116,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"v5yIQP8RYl7O","outputId":"8e7ddd3c-39f2-438c-ae23-ed75a0092db0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Params to learn:\n","\t conv1.weight\n","\t bn1.weight\n","\t bn1.bias\n","\t layer1.0.conv1.weight\n","\t layer1.0.bn1.weight\n","\t layer1.0.bn1.bias\n","\t layer1.0.conv2.weight\n","\t layer1.0.bn2.weight\n","\t layer1.0.bn2.bias\n","\t layer1.0.conv3.weight\n","\t layer1.0.bn3.weight\n","\t layer1.0.bn3.bias\n","\t layer1.0.downsample.0.weight\n","\t layer1.0.downsample.1.weight\n","\t layer1.0.downsample.1.bias\n","\t layer1.1.conv1.weight\n","\t layer1.1.bn1.weight\n","\t layer1.1.bn1.bias\n","\t layer1.1.conv2.weight\n","\t layer1.1.bn2.weight\n","\t layer1.1.bn2.bias\n","\t layer1.1.conv3.weight\n","\t layer1.1.bn3.weight\n","\t layer1.1.bn3.bias\n","\t layer1.2.conv1.weight\n","\t layer1.2.bn1.weight\n","\t layer1.2.bn1.bias\n","\t layer1.2.conv2.weight\n","\t layer1.2.bn2.weight\n","\t layer1.2.bn2.bias\n","\t layer1.2.conv3.weight\n","\t layer1.2.bn3.weight\n","\t layer1.2.bn3.bias\n","\t layer2.0.conv1.weight\n","\t layer2.0.bn1.weight\n","\t layer2.0.bn1.bias\n","\t layer2.0.conv2.weight\n","\t layer2.0.bn2.weight\n","\t layer2.0.bn2.bias\n","\t layer2.0.conv3.weight\n","\t layer2.0.bn3.weight\n","\t layer2.0.bn3.bias\n","\t layer2.0.downsample.0.weight\n","\t layer2.0.downsample.1.weight\n","\t layer2.0.downsample.1.bias\n","\t layer2.1.conv1.weight\n","\t layer2.1.bn1.weight\n","\t layer2.1.bn1.bias\n","\t layer2.1.conv2.weight\n","\t layer2.1.bn2.weight\n","\t layer2.1.bn2.bias\n","\t layer2.1.conv3.weight\n","\t layer2.1.bn3.weight\n","\t layer2.1.bn3.bias\n","\t layer2.2.conv1.weight\n","\t layer2.2.bn1.weight\n","\t layer2.2.bn1.bias\n","\t layer2.2.conv2.weight\n","\t layer2.2.bn2.weight\n","\t layer2.2.bn2.bias\n","\t layer2.2.conv3.weight\n","\t layer2.2.bn3.weight\n","\t layer2.2.bn3.bias\n","\t layer2.3.conv1.weight\n","\t layer2.3.bn1.weight\n","\t layer2.3.bn1.bias\n","\t layer2.3.conv2.weight\n","\t layer2.3.bn2.weight\n","\t layer2.3.bn2.bias\n","\t layer2.3.conv3.weight\n","\t layer2.3.bn3.weight\n","\t layer2.3.bn3.bias\n","\t layer3.0.conv1.weight\n","\t layer3.0.bn1.weight\n","\t layer3.0.bn1.bias\n","\t layer3.0.conv2.weight\n","\t layer3.0.bn2.weight\n","\t layer3.0.bn2.bias\n","\t layer3.0.conv3.weight\n","\t layer3.0.bn3.weight\n","\t layer3.0.bn3.bias\n","\t layer3.0.downsample.0.weight\n","\t layer3.0.downsample.1.weight\n","\t layer3.0.downsample.1.bias\n","\t layer3.1.conv1.weight\n","\t layer3.1.bn1.weight\n","\t layer3.1.bn1.bias\n","\t layer3.1.conv2.weight\n","\t layer3.1.bn2.weight\n","\t layer3.1.bn2.bias\n","\t layer3.1.conv3.weight\n","\t layer3.1.bn3.weight\n","\t layer3.1.bn3.bias\n","\t layer3.2.conv1.weight\n","\t layer3.2.bn1.weight\n","\t layer3.2.bn1.bias\n","\t layer3.2.conv2.weight\n","\t layer3.2.bn2.weight\n","\t layer3.2.bn2.bias\n","\t layer3.2.conv3.weight\n","\t layer3.2.bn3.weight\n","\t layer3.2.bn3.bias\n","\t layer3.3.conv1.weight\n","\t layer3.3.bn1.weight\n","\t layer3.3.bn1.bias\n","\t layer3.3.conv2.weight\n","\t layer3.3.bn2.weight\n","\t layer3.3.bn2.bias\n","\t layer3.3.conv3.weight\n","\t layer3.3.bn3.weight\n","\t layer3.3.bn3.bias\n","\t layer3.4.conv1.weight\n","\t layer3.4.bn1.weight\n","\t layer3.4.bn1.bias\n","\t layer3.4.conv2.weight\n","\t layer3.4.bn2.weight\n","\t layer3.4.bn2.bias\n","\t layer3.4.conv3.weight\n","\t layer3.4.bn3.weight\n","\t layer3.4.bn3.bias\n","\t layer3.5.conv1.weight\n","\t layer3.5.bn1.weight\n","\t layer3.5.bn1.bias\n","\t layer3.5.conv2.weight\n","\t layer3.5.bn2.weight\n","\t layer3.5.bn2.bias\n","\t layer3.5.conv3.weight\n","\t layer3.5.bn3.weight\n","\t layer3.5.bn3.bias\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.conv3.weight\n","\t layer4.0.bn3.weight\n","\t layer4.0.bn3.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t layer4.1.conv3.weight\n","\t layer4.1.bn3.weight\n","\t layer4.1.bn3.bias\n","\t layer4.2.conv1.weight\n","\t layer4.2.bn1.weight\n","\t layer4.2.bn1.bias\n","\t layer4.2.conv2.weight\n","\t layer4.2.bn2.weight\n","\t layer4.2.bn2.bias\n","\t layer4.2.conv3.weight\n","\t layer4.2.bn3.weight\n","\t layer4.2.bn3.bias\n","\t fc.weight\n","\t fc.bias\n"]},{"data":{"text/plain":["SGD (\n","Parameter Group 0\n","    dampening: 0\n","    lr: 0.001\n","    momentum: 0.9\n","    nesterov: False\n","    weight_decay: 0\n",")"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["model = model.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized    \n","#learning_rate = 0.001\n","#optimizer_ft = optim.Adam(params_to_update, lr=learning_rate)\n","optim.SGD(params_to_update, lr=0.001, momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"E4vZ2gUhYqdn"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/14\n","----------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 4.7584 Acc: 0.0107\n","val Loss: 4.5970 Acc: 0.0049\n","\n","Epoch 1/14\n","----------\n","train Loss: 4.4688 Acc: 0.0410\n","val Loss: 4.5212 Acc: 0.0243\n","\n","Epoch 2/14\n","----------\n","train Loss: 4.0952 Acc: 0.0891\n","val Loss: 4.4119 Acc: 0.0291\n","\n","Epoch 3/14\n","----------\n","train Loss: 3.6374 Acc: 0.2210\n","val Loss: 4.3175 Acc: 0.0388\n","\n","Epoch 4/14\n","----------\n","train Loss: 3.1561 Acc: 0.3458\n","val Loss: 4.1627 Acc: 0.0874\n","\n","Epoch 5/14\n","----------\n","train Loss: 2.6398 Acc: 0.5633\n","val Loss: 4.0258 Acc: 0.1019\n","\n","Epoch 6/14\n","----------\n","train Loss: 2.0905 Acc: 0.7487\n","val Loss: 3.9195 Acc: 0.1117\n","\n","Epoch 7/14\n","----------\n","train Loss: 1.6041 Acc: 0.8663\n","val Loss: 3.8519 Acc: 0.1456\n","\n","Epoch 8/14\n","----------\n","train Loss: 1.2043 Acc: 0.9234\n","val Loss: 3.7971 Acc: 0.1942\n","\n","Epoch 9/14\n","----------\n","train Loss: 0.8062 Acc: 0.9768\n","val Loss: 3.7491 Acc: 0.1796\n","\n","Epoch 10/14\n","----------\n","train Loss: 0.5380 Acc: 0.9893\n","val Loss: 3.7104 Acc: 0.1990\n","\n","Epoch 11/14\n","----------\n","train Loss: 0.3674 Acc: 0.9964\n","val Loss: 3.6611 Acc: 0.1845\n","\n","Epoch 12/14\n","----------\n","train Loss: 0.2884 Acc: 0.9982\n","val Loss: 3.6673 Acc: 0.2039\n","\n","Epoch 13/14\n","----------\n","train Loss: 0.2142 Acc: 0.9964\n","val Loss: 3.6408 Acc: 0.1796\n","\n","Epoch 14/14\n","----------\n","train Loss: 0.1732 Acc: 0.9982\n","val Loss: 3.6762 Acc: 0.1942\n","\n","Training complete in 5m 27s\n","Best val Acc: 0.203883\n"]}],"source":["criterion = nn.CrossEntropyLoss()\n","\n","# Train and evaluate\n","model, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1641671477151,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"--nvAeenaMjS"},"outputs":[],"source":["torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/ibb_ass3/modelresnet50scg-perfectlyannot.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1641671477152,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"dwPuxJ06fnp6"},"outputs":[],"source":["import joblib as joblib\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1641671477153,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"aL621KLKaUBg"},"outputs":[],"source":["joblib.dump([hist], '/content/drive/MyDrive/Colab Notebooks/ibb_ass3/histogram.joblib')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"aborted","timestamp":1641671477159,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"iEDWh2CLhsby"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":27,"status":"aborted","timestamp":1641671477160,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"K7JDXhbzjLcU"},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"aborted","timestamp":1641671477162,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"sPulQ_gjoYi4"},"outputs":[],"source":["from PIL import Image, ImageDraw\n","import torchvision.transforms\n","from torch.autograd import Variable\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"aborted","timestamp":1641671477163,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"CwyyiqNnsb98"},"outputs":[],"source":["def predict_image(path):\n","    #print(\"Prediction in progress\")\n","    image = Image.open(path)\n","\n","    transformation = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","\n","    img_tensor = transformation(image).float()\n","    img_tensor = img_tensor.unsqueeze_(0)\n","\n","    #if torch.cuda.is_available():\n","    #    img_tensor.cuda()\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    img_tensor = img_tensor.to(device)\n","    \n","    input = Variable(img_tensor)\n","    output = model(input)\n","    index = output.cpu().data.numpy().argmax() + 1\n","\n","    return index\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30,"status":"aborted","timestamp":1641671477164,"user":{"displayName":"Zala Eric","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13008992118458069302"},"user_tz":-60},"id":"UGVsKrjMeyyx"},"outputs":[],"source":["import numpy as np\n","import os\n","import csv\n","from keras.preprocessing import image\n","from openpyxl import load_workbook\n","\n","wb = load_workbook('/content/drive/MyDrive/Colab Notebooks/ibb_ass3/recognition.xlsx')\n","dict1 = {}\n","\n","for row in wb.worksheets[0].iter_rows():\n","   dict1[(row[0].value)] = row[1].value\n","\n","directory = os.fsencode('/content/drive/MyDrive/Colab Notebooks/ibb_ass3/cropped2/')\n","count = 0;\n","for file in os.listdir(directory):\n","     #print('####'*10)\n","     filename = os.fsdecode(file)\n","     ImagePath = '/content/drive/MyDrive/Colab Notebooks/ibb_ass3/cropped2/' + filename;\n","     #print(ImagePath)\n","     prediction = predict_image(ImagePath)\n","\n","     #print('Prediction is: ', prediction)\n","     #print('It should be: ', dict1[\"./test/\" + filename])\n","     if (int(prediction) == int(dict1[\"./test/\" + filename])):\n","       #print(\"SUCCESS\");\n","       count = count + 1;\n","       #print(count);\n","     #with open('results.csv', mode='a') as employee_file:\n","      #employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","      #employee_writer.writerow([ImagePath, ResultMap[np.argmax(result)], sorted(zip(result[0], list(training_set.class_indices.keys())), reverse=True)[:3]])\n","\n","print(count)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPGyJ7m5a0mUbX1Qn3gRMVL","collapsed_sections":[],"name":"Untitled1.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}